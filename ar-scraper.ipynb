{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import  requests \n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.error import URLError, HTTPError\n",
    "from urllib3.exceptions import SSLError\n",
    "\n",
    "from requests.exceptions import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from socket import timeout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnadoluJet 7/7 AnadoluJet\n",
      "['737-800', 'Ej-195']\n",
      "---------\n",
      "\n",
      "Turkish Airlines 7/7 Turkish Airlines\n",
      "['737-800', 'Ej-195', 'A340-300', 'A330-200', 'A330-300', '777-300ER', '737-900ER', '737-800', '737-700', 'A321', 'A320']\n",
      "---------\n",
      "\n",
      "Pegasus 6/7 Pegasus\n",
      "['737-800', 'Ej-195', 'A340-300', 'A330-200', 'A330-300', '777-300ER', '737-900ER', '737-800', '737-700', 'A321', 'A320', 'A320']\n",
      "---------\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "aircrafts = []\n",
    "urls = ['https://www.airlineratings.com/ratings/anadolujet/#aircraft_types_tab','https://www.airlineratings.com/ratings/turkish-airlines/#aircraft_types_tab','https://www.airlineratings.com/ratings/pegasus/#aircraft_types_tab']\n",
    "\n",
    "writer = open('datasets/airlines_info.csv','w+')\n",
    "for url in urls:\n",
    "    try: \n",
    "        \n",
    "        \n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "        reg_url = url\n",
    "        req = Request(url=reg_url, headers=headers) \n",
    "        html = urlopen(req).read()  \n",
    "\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "        airline = str(soup.find('title').text).split('-')[0].strip()\n",
    "        airline_data = str(soup.find_all('div',{'class':'airline_rating'}))\n",
    "        safety_rating = airline_data.split('Safety Rating')[1].split('</')[0].strip()\n",
    "        product_rating = airline_data.split('Product Rating')[1].split('</')[0].strip()\n",
    "        \n",
    "        airc = str(soup.find_all('div',{'id':'aircraft_types_tab'})).split('<li>')\n",
    "#         print(airc.split('<li>'))\n",
    "        for i in range(1,len(airc)-1,1):\n",
    "            aircrafts.append(airc[i].split('</')[0].strip())\n",
    "        \n",
    "        print(airline,safety_rating,airline)\n",
    "        print(aircrafts)\n",
    "        print('---------\\n')\n",
    "\n",
    "        \n",
    "        writer.write(f\"{airline},{safety_rating},{product_rating},{aircrafts}\\n\")\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    except HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')  \n",
    "        pass\n",
    "    except Exception as err:\n",
    "        print(f'Other1 error occurred: {err}')  \n",
    "        pass\n",
    "    \n",
    "writer.close()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
